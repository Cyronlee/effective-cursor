---
title: "Automated Testing"
---

import { Steps } from 'nextra/components'

# Automated Testing

> Let automated tests verify the correctness of AI-generated code

## Core Concept

In AI-assisted development, automated testing tools are **not replaced by AI**, but serve as reliable verification mechanisms integrated into the Agent's feedback loop.

### AI + Testing Collaboration Loop

<Steps>

### AI Generates Code

AI Agent quickly generates functional code

### Run Test Suite

Automated tests check functional correctness

### Get Failure Report

Extract failed cases, expected vs actual values

### AI Targeted Fixes

AI fixes based on specific error messages

### Repeat Until Passing

Loop until all tests pass

</Steps>

### Division of Work

| Role | Strengths |
|------|-----------|
| **AI** | Quickly generate functional code, explore implementation solutions, refactor logic |
| **Automated Tests** | Check functional correctness, boundary conditions, regression issues, integration behavior |

This division is more efficient and reliable than "letting AI self-verify":

- Tests provide **objective, repeatable** deterministic feedback
- Avoids AI hallucinations, self-consistent bias, or missed edge cases
- Naturally fits existing engineering practices (CI/CD, TDD/BDD)

## Testing Framework Quick Reference

| Language | Unit Testing | Component/Integration | E2E Testing |
|----------|-------------|----------------------|-------------|
| TypeScript | Vitest / Jest | Testing Library | Playwright / Cypress |
| Python | PyTest | PyTest | Playwright / Selenium |
| Java | JUnit 5 | Spring Boot Test | Selenium |
| Go | testing | testify | chromedp |

## JavaScript / TypeScript Testing

### Recommended Frameworks

| Framework | Type | Features | Recommendation |
|-----------|------|----------|----------------|
| **Vitest** | Unit Testing | Fast, integrates with Vite | ‚≠ê‚≠ê‚≠ê |
| **Jest** | Unit Testing | Mature, rich ecosystem | ‚≠ê‚≠ê |
| **Testing Library** | Component Testing | User-perspective testing | ‚≠ê‚≠ê‚≠ê |
| **Playwright** | E2E Testing | Cross-browser, reliable | ‚≠ê‚≠ê‚≠ê |
| **Cypress** | E2E Testing | Great developer experience | ‚≠ê‚≠ê |

## Python Testing

### Recommended Frameworks

| Framework | Type | Features | Recommendation |
|-----------|------|----------|----------------|
| **PyTest** | Unit/Integration | Flexible, rich plugins | ‚≠ê‚≠ê‚≠ê |
| **unittest** | Unit Testing | Standard library, stable | ‚≠ê‚≠ê |
| **pytest-asyncio** | Async Testing | Async code support | ‚≠ê‚≠ê‚≠ê |
| **pytest-cov** | Coverage | Coverage reporting | ‚≠ê‚≠ê‚≠ê |

## Java Testing

| Framework | Type | Features |
|-----------|------|----------|
| **JUnit 5** | Unit Testing | Modern, feature-rich |
| **Mockito** | Mock Framework | Easy-to-use mocking |
| **AssertJ** | Assertion Library | Fluent assertion API |
| **Spring Boot Test** | Integration Testing | Spring ecosystem integration |

## Test Types Explained

| Type | Purpose | Speed | Coverage Scope |
|------|---------|-------|----------------|
| **Unit Tests** | Test single functions/methods | üöÄ Fastest | Fine-grained |
| **Component Tests** | Test UI component behavior | ‚ö° Fast | Component level |
| **Integration Tests** | Test module interactions | üèÉ Medium | Module level |
| **E2E Tests** | Test complete user flows | üê¢ Slower | Global |

## AI Collaboration Best Practices

### Test-Driven AI Development (TDD)

| Step | Actor | Description |
|------|-------|-------------|
| 1. Write Tests | Human | Define expected behavior first |
| 2. Implement Code | AI | Implement based on tests |
| 3. Run Tests | Automation | Verify implementation |
| 4. Fix | AI | Fix based on failure reports |

### Feeding Test Failures to AI

Effective feedback should include:

| Information | Description |
|-------------|-------------|
| **Test Case Name** | Which test failed |
| **Expected Value** | What was expected |
| **Actual Value** | What was actually received |
| **Related Code Location** | File and line number |
| **Stack Trace** | Error stack (if available) |

### Coverage-Driven

| Practice | Description |
|----------|-------------|
| Generate coverage reports | Understand which code isn't tested |
| Set coverage thresholds | e.g., 80% line coverage |
| Have AI supplement tests | Generate tests for uncovered branches |

## Configuration Checklist

| Category | Check Item |
|----------|------------|
| **Framework** | ‚úÖ Test framework installed and configured |
| **Environment** | ‚úÖ Test environment isolated (e.g., jsdom) |
| **Coverage** | ‚úÖ Coverage tool configured |
| **CI Integration** | ‚úÖ Tests run automatically in CI |
| **Mocking** | ‚úÖ Mock tools ready (e.g., vi.fn/Mock) |
| **Data** | ‚úÖ Test data/fixtures organized |

## Next Steps

After configuring the testing framework, set up [CI/CD Pipeline](./ci-cd) to automate the entire development process.
